import logging
import json
import os
import re
from dotenv import load_dotenv
from langchain_core.runnables import RunnableLambda
from langchain.prompts import PromptTemplate
from langchain.memory import ConversationBufferMemory
from langchain_deepseek import ChatDeepSeek
from agents.telegram_agent import TelegramAgent
from agents.github_agent import GitHubAgent
from agents.tavily_agent import TavilyAgent

# –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è
load_dotenv()

logger = logging.getLogger(__name__)

# –ó–∞–≥—Ä—É–∂–∞–µ–º –∫–ª—é—á–∏ API
DEEPSEEK_API_KEY = os.getenv("OPENAI_API_KEY")
DEEPSEEK_BASE_URL = os.getenv("OPENAI_API_BASE_URL", "https://api.deepseek.com/v1")
DEEPSEEK_MODEL = os.getenv("OPENAI_API_MODEL", "deepseek-chat")

# –°–æ–∑–¥–∞–µ–º LLM –º–æ–¥–µ–ª—å DeepSeek
llm = ChatDeepSeek(
    model=DEEPSEEK_MODEL,
    api_key=DEEPSEEK_API_KEY,
    temperature=0.7,
    api_base=DEEPSEEK_BASE_URL
)

# –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–∞–º—è—Ç—å
memory = ConversationBufferMemory(memory_key="history")


# --- –î–µ–∫–æ—Ä–∞—Ç–æ—Ä –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è —à–∞–≥–æ–≤ ---
def log_step(step_name):
    def decorator(func):
        def wrapper(*args, **kwargs):
            logger.info(f"üîπ –ù–∞—á–∏–Ω–∞–µ–º —à–∞–≥: {step_name}")
            result = func(*args, **kwargs)
            logger.info(f"‚úÖ –ó–∞–≤–µ—Ä—à–µ–Ω —à–∞–≥: {step_name}, —Ä–µ–∑—É–ª—å—Ç–∞—Ç: {result}")
            return result
        return wrapper
    return decorator


# --- 1. –ê–Ω–∞–ª–∏–∑ –∑–∞–¥–∞—á–∏ ---
def clean_and_parse_response(response):
    """–û—á–∏—â–∞–µ—Ç JSON-–æ—Ç–≤–µ—Ç –æ—Ç <think>...<think> –∏ –ø–∞—Ä—Å–∏—Ç –µ–≥–æ."""
    try:
        content = response.content.strip()
        
        # –£–±–∏—Ä–∞–µ–º <think>...</think>
        clean_json = re.sub(r"<think>.*?</think>", "", content, flags=re.DOTALL).strip()
        
        # –î–µ–∫–æ–¥–∏—Ä—É–µ–º JSON
        parsed_json = json.loads(clean_json)

        logger.info(f"üìä –ê–Ω–∞–ª–∏–∑ –∑–∞–¥–∞—á–∏: {parsed_json}")  # –õ–æ–≥–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞

        return parsed_json
    
    except json.JSONDecodeError:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ JSON: {response.content}")
        return {"summary": "–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞", "tools": []}  # –ë–µ–∑–æ–ø–∞—Å–Ω—ã–π fallback


analyze_prompt = PromptTemplate(
    input_variables=["task_description"],
    template="""
    –¢—ã AI-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç. –û–ø—Ä–µ–¥–µ–ª–∏, –∫–∞–∫–∏–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã (GitHub, Twitter, Telegram, Tavily) 
    –Ω—É–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–¥–∞—á–∏.

    –ü—Ä–∏–º–µ—Ä –æ—Ç–≤–µ—Ç–∞:
    {{
        "summary": "–ó–∞–¥–∞—á–∞ —Ç—Ä–µ–±—É–µ—Ç –ø—É–±–ª–∏–∫–∞—Ü–∏–∏ –≤ Twitter –∏ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è –≤ Telegram.",
        "tools": ["twitter", "telegram"]
    }}

    –í–∞–∂–Ω–æ: –í–µ—Ä–Ω–∏ JSON –±–µ–∑ –ª–∏—à–Ω–µ–≥–æ —Ç–µ–∫—Å—Ç–∞!

    –í—Ö–æ–¥–Ω–∞—è –∑–∞–¥–∞—á–∞: {task_description}
    """
)


def parse_analysis_response(response):
    """–ü–∞—Ä—Å–∏—Ç JSON-–æ—Ç–≤–µ—Ç –æ—Ç –º–æ–¥–µ–ª–∏, —Å–æ—Ö—Ä–∞–Ω—è—è –∏—Å—Ö–æ–¥–Ω—ã–π task_description."""
    try:
        content = response.content.strip()
        clean_json = re.sub(r"<think>.*?</think>", "", content, flags=re.DOTALL).strip()
        parsed_json = json.loads(clean_json)
        
        logger.info(f"üìä –†–∞–∑–æ–±—Ä–∞–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑: {parsed_json}")
        
        return {
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏—Å—Ö–æ–¥–Ω—ã–π task_description –∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
            "task_description": response.task_description,  
            "analysis": parsed_json
        }
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞: {e}")
        return {
            "task_description": response.task_description,
            "analysis": {"summary": "–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞", "tools": []}
        }


analyze_chain = (
    RunnableLambda(lambda x: {"input_task": x})
    | analyze_prompt
    | llm
    | RunnableLambda(lambda response: parse_analysis_response(
        # –ü–µ—Ä–µ–¥–∞–µ–º –∏—Å—Ö–æ–¥–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –∑–∞–¥–∞—á–∏ –≤ –ø–∞—Ä—Å–µ—Ä
        response.with_task_description(response.context["input_task"])
    ))
)


# analyze_chain = analyze_prompt | llm | RunnableLambda(lambda response: {"analysis": clean_and_parse_response(response)})
# analyze_chain = (
#     RunnableLambda(lambda x: {"task_description": x})  # –ü–µ—Ä–µ–¥–∞–µ–º –∑–∞–¥–∞—á—É –¥–∞–ª—å—à–µ
#     | analyze_prompt
#     | llm
#     | RunnableLambda(lambda response: {
#         "task_description": response["task_description"],  # –¢–µ–ø–µ—Ä—å –ø–µ—Ä–µ–¥–∞–µ–º –¥–∞–ª—å—à–µ
#         "analysis": clean_and_parse_response(response)
#     })
# )


# --- 2. –ü–æ–∏—Å–∫ –≤ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–µ ---
@log_step("–ü–æ–∏—Å–∫ –≤ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–µ")
def search_internet(inputs):
    """–ü–æ–∏—Å–∫ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏, –µ—Å–ª–∏ Tavily –≤–∫–ª—é—á–µ–Ω –≤ —Å–ø–∏—Å–æ–∫ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤."""
    analysis = inputs.get("analysis", {})
    task_description = inputs["task_description"]

    logger.info(f"üì• –í—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –≤ –ø–æ–∏—Å–∫: {inputs}")

    if not analysis.get("tools"):
        logger.warning("‚ö†Ô∏è –í–Ω–∏–º–∞–Ω–∏–µ: —Å–ø–∏—Å–æ–∫ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤ –ø—É—Å—Ç! –ê–Ω–∞–ª–∏–∑ –º–æ–∂–µ—Ç –±—ã—Ç—å –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–º.")
    
    if not task_description:
        logger.error("‚ùå –û—à–∏–±–∫–∞: `task_description` –ø—É—Å—Ç–æ–π, –Ω–µ–≤–æ–∑–º–æ–∂–Ω–æ –≤—ã–ø–æ–ª–Ω–∏—Ç—å –ø–æ–∏—Å–∫.")
        return {"analysis": analysis, "task_description": task_description, "internet_results": []}

    tavily_agent = TavilyAgent()

    try:
        search_results = tavily_agent.search(task_description) if "tavily" in analysis.get("tools", []) else []
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–∏ –ø–æ–∏—Å–∫–∞: {e}")
        search_results = []

    return {"analysis": analysis, "task_description": task_description, "internet_results": search_results}

# --- 3. –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∑–∞–¥–∞—á–∏ ---
@log_step("–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∑–∞–¥–∞—á–∏")
def execute_task(inputs):
    """–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∑–∞–¥–∞—á–∏ —Å –Ω—É–∂–Ω—ã–º–∏ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞–º–∏."""
    analysis = inputs.get("analysis", {})
    task_description = inputs.get("task_description", "")
    tools = analysis.get("tools", [])

    logger.info(f"üì• –í—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –≤ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ: {inputs}")  # –õ–æ–≥–∏—Ä—É–µ–º –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ

    if not tools:
        logger.warning("‚ö†Ô∏è –í–Ω–∏–º–∞–Ω–∏–µ: –Ω–µ—Ç –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è! –í–æ–∑–º–æ–∂–Ω–æ, –æ—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞.")

    results = []

    if "telegram" in tools:
        telegram_agent = TelegramAgent()
        result = telegram_agent.send_message(f"üîî –í—ã–ø–æ–ª–Ω—è—é –∑–∞–¥–∞—á—É: {task_description}")
        results.append(f"üì¢ Telegram: {result}")

    if "github" in tools:
        github_agent = GitHubAgent()
        repo_name = "ai-agent-tasks"
        result = github_agent.create_issue(repo_name, "AI Task", task_description)
        results.append(f"üîß GitHub Issue: {result}")

    return {"analysis": analysis, "execution_results": results}


# --- 4. –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞ ---
@log_step("–§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞")
def summarize_result(inputs):
    """–§–æ—Ä–º–∏—Ä—É–µ—Ç —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç."""
    execution_results = inputs.get("execution_results", [])

    if not execution_results:
        response = "‚ö†Ô∏è –û—à–∏–±–∫–∞! –ù–∏–∫–∞–∫–∏–µ –¥–µ–π—Å—Ç–≤–∏—è –Ω–µ –±—ã–ª–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω—ã."
        logger.error(response)
    else:
        response = f"‚úÖ –ó–∞–¥–∞—á–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∞!\n{'\n'.join(execution_results)}"

    return {"response": response}


# --- –°–æ–±–∏—Ä–∞–µ–º –ø–∞–π–ø–ª–∞–π–Ω ---
def build_agent_chain():
    """–°–æ–∑–¥–∞–µ—Ç —Ü–µ–ø–æ—á–∫—É –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å –ª–æ–≥–∞–º–∏."""
    return (
        RunnableLambda(lambda x: {"task_description": x})  # –ù–∞—á–∞–ª–æ (–≤—Ö–æ–¥)
        | analyze_chain
        | RunnableLambda(search_internet)
        | RunnableLambda(execute_task)
        | RunnableLambda(summarize_result)
    )
